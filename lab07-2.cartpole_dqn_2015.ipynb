{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-18 15:42:30,620] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import dqn\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Constants defining our neural network\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "dis = 0.9\n",
    "REPLAY_MEMORY = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replay_train(mainDQN, targetDQN, train_batch):\n",
    "    x_stack = np.empty(0).reshape(0, input_size)\n",
    "    y_stack = np.empty(0).reshape(0, output_size)\n",
    "    \n",
    "    #Get stored information from the buffer\n",
    "    for state, action, reward, next_state, done in train_batch:\n",
    "        Q = mainDQN.predict(state)\n",
    "        \n",
    "        # terminal?\n",
    "        if done:\n",
    "            Q[0, action] = reward\n",
    "        else:\n",
    "            # get target from target DQN (Q')\n",
    "            Q[0, action] = reward + dis * np.max(targetDQN.predict(next_state))\n",
    "\n",
    "        y_stack = np.vstack([y_stack, Q])\n",
    "        x_stack = np.vstack([x_stack, state])\n",
    "        \n",
    "    #Train our network using target and predicted Q values on each episode\n",
    "    return mainDQN.update(x_stack, y_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bot_play(mainDQN):\n",
    "    # See our trained network in action\n",
    "    s = env.reset()\n",
    "    reward_sum = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        a = np.argmax(mainDQN.predict(s))\n",
    "        s, reward, done, _ = env.step(a)\n",
    "        reward_sum += reward\n",
    "        if done:\n",
    "            print(\"Toral score: {}\".format(reward_sum))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_copy_var_ops(*, dest_scope_name=\"target\", src_scope_name=\"main\"):\n",
    "    # Copy variables src_scope to dest_scope\n",
    "    op_holder = []\n",
    "    \n",
    "    src_vars = tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=src_scope_name)\n",
    "    dest_vars = tf.get_collection(\n",
    "        tf.GraphKeys.TRAINABLE_VARIABLES, scope=dest_scope_name)\n",
    "    \n",
    "    for src_var, dest_var in zip(src_vars, dest_vars):\n",
    "        op_holder.append(dest_var.assign(src_var.value()))\n",
    "        \n",
    "    return op_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0    steps: 14      streaks: 0\n",
      "Episode: 1    steps: 11      streaks: 0\n",
      "Loss:  471.526\n",
      "Episode: 2    steps: 14      streaks: 0\n",
      "Episode: 3    steps: 10      streaks: 0\n",
      "Episode: 4    steps: 22      streaks: 0\n",
      "Episode: 5    steps: 11      streaks: 0\n",
      "Episode: 6    steps: 12      streaks: 0\n",
      "Episode: 7    steps: 13      streaks: 0\n",
      "Episode: 8    steps: 15      streaks: 0\n",
      "Episode: 9    steps: 17      streaks: 0\n",
      "Episode: 10    steps: 15      streaks: 0\n",
      "Episode: 11    steps: 12      streaks: 0\n",
      "Loss:  943.592\n",
      "Episode: 12    steps: 77      streaks: 0\n",
      "Episode: 13    steps: 69      streaks: 0\n",
      "Episode: 14    steps: 110      streaks: 0\n",
      "Episode: 15    steps: 75      streaks: 0\n",
      "Episode: 16    steps: 110      streaks: 0\n",
      "Episode: 17    steps: 83      streaks: 0\n",
      "Episode: 18    steps: 66      streaks: 0\n",
      "Episode: 19    steps: 99      streaks: 0\n",
      "Episode: 20    steps: 115      streaks: 0\n",
      "Episode: 21    steps: 60      streaks: 0\n",
      "Loss:  526.781\n",
      "Episode: 22    steps: 46      streaks: 0\n",
      "Episode: 23    steps: 41      streaks: 0\n",
      "Episode: 24    steps: 47      streaks: 0\n",
      "Episode: 25    steps: 34      streaks: 0\n",
      "Episode: 26    steps: 32      streaks: 0\n",
      "Episode: 27    steps: 37      streaks: 0\n",
      "Episode: 28    steps: 65      streaks: 0\n",
      "Episode: 29    steps: 55      streaks: 0\n",
      "Episode: 30    steps: 55      streaks: 0\n",
      "Episode: 31    steps: 41      streaks: 0\n",
      "Loss:  462.533\n",
      "Episode: 32    steps: 128      streaks: 0\n",
      "Episode: 33    steps: 86      streaks: 0\n",
      "Episode: 34    steps: 51      streaks: 0\n",
      "Episode: 35    steps: 66      streaks: 0\n",
      "Episode: 36    steps: 60      streaks: 0\n",
      "Episode: 37    steps: 57      streaks: 0\n",
      "Episode: 38    steps: 101      streaks: 0\n",
      "Episode: 39    steps: 71      streaks: 0\n",
      "Episode: 40    steps: 48      streaks: 0\n",
      "Episode: 41    steps: 69      streaks: 0\n",
      "Loss:  2.25902\n",
      "Episode: 42    steps: 95      streaks: 0\n",
      "Episode: 43    steps: 60      streaks: 0\n",
      "Episode: 44    steps: 90      streaks: 0\n",
      "Episode: 45    steps: 79      streaks: 0\n",
      "Episode: 46    steps: 94      streaks: 0\n",
      "Episode: 47    steps: 69      streaks: 0\n",
      "Episode: 48    steps: 65      streaks: 0\n",
      "Episode: 49    steps: 66      streaks: 0\n",
      "Episode: 50    steps: 110      streaks: 0\n",
      "Episode: 51    steps: 77      streaks: 0\n",
      "Loss:  411.414\n",
      "Episode: 52    steps: 26      streaks: 0\n",
      "Episode: 53    steps: 21      streaks: 0\n",
      "Episode: 54    steps: 39      streaks: 0\n",
      "Episode: 55    steps: 27      streaks: 0\n",
      "Episode: 56    steps: 59      streaks: 0\n",
      "Episode: 57    steps: 29      streaks: 0\n",
      "Episode: 58    steps: 19      streaks: 0\n",
      "Episode: 59    steps: 23      streaks: 0\n",
      "Episode: 60    steps: 14      streaks: 0\n",
      "Episode: 61    steps: 19      streaks: 0\n",
      "Loss:  2.43225\n",
      "Episode: 62    steps: 83      streaks: 0\n",
      "Episode: 63    steps: 92      streaks: 0\n",
      "Episode: 64    steps: 61      streaks: 0\n",
      "Episode: 65    steps: 49      streaks: 0\n",
      "Episode: 66    steps: 49      streaks: 0\n",
      "Episode: 67    steps: 72      streaks: 0\n",
      "Episode: 68    steps: 94      streaks: 0\n",
      "Episode: 69    steps: 49      streaks: 0\n",
      "Episode: 70    steps: 49      streaks: 0\n",
      "Episode: 71    steps: 84      streaks: 0\n",
      "Loss:  4.65501\n",
      "Episode: 72    steps: 8      streaks: 0\n",
      "Episode: 73    steps: 10      streaks: 0\n",
      "Episode: 74    steps: 9      streaks: 0\n",
      "Episode: 75    steps: 12      streaks: 0\n",
      "Episode: 76    steps: 9      streaks: 0\n",
      "Episode: 77    steps: 11      streaks: 0\n",
      "Episode: 78    steps: 8      streaks: 0\n",
      "Episode: 79    steps: 10      streaks: 0\n",
      "Episode: 80    steps: 9      streaks: 0\n",
      "Episode: 81    steps: 10      streaks: 0\n",
      "Loss:  627.995\n",
      "Episode: 82    steps: 10      streaks: 0\n",
      "Episode: 83    steps: 12      streaks: 0\n",
      "Episode: 84    steps: 10      streaks: 0\n",
      "Episode: 85    steps: 9      streaks: 0\n",
      "Episode: 86    steps: 10      streaks: 0\n",
      "Episode: 87    steps: 11      streaks: 0\n",
      "Episode: 88    steps: 10      streaks: 0\n",
      "Episode: 89    steps: 10      streaks: 0\n",
      "Episode: 90    steps: 12      streaks: 0\n",
      "Episode: 91    steps: 10      streaks: 0\n",
      "Loss:  2.73923\n",
      "Episode: 92    steps: 22      streaks: 0\n",
      "Episode: 93    steps: 57      streaks: 0\n",
      "Episode: 94    steps: 24      streaks: 0\n",
      "Episode: 95    steps: 24      streaks: 0\n",
      "Episode: 96    steps: 18      streaks: 0\n",
      "Episode: 97    steps: 29      streaks: 0\n",
      "Episode: 98    steps: 26      streaks: 0\n",
      "Episode: 99    steps: 19      streaks: 0\n",
      "Episode: 100    steps: 31      streaks: 0\n",
      "Episode: 101    steps: 19      streaks: 0\n",
      "Loss:  6.25831\n",
      "Episode: 102    steps: 17      streaks: 0\n",
      "Episode: 103    steps: 41      streaks: 0\n",
      "Episode: 104    steps: 38      streaks: 0\n",
      "Episode: 105    steps: 22      streaks: 0\n",
      "Episode: 106    steps: 32      streaks: 0\n",
      "Episode: 107    steps: 19      streaks: 0\n",
      "Episode: 108    steps: 15      streaks: 0\n",
      "Episode: 109    steps: 20      streaks: 0\n",
      "Episode: 110    steps: 37      streaks: 0\n",
      "Episode: 111    steps: 33      streaks: 0\n",
      "Loss:  518.476\n",
      "Episode: 112    steps: 50      streaks: 0\n",
      "Episode: 113    steps: 46      streaks: 0\n",
      "Episode: 114    steps: 49      streaks: 0\n",
      "Episode: 115    steps: 32      streaks: 0\n",
      "Episode: 116    steps: 49      streaks: 0\n",
      "Episode: 117    steps: 27      streaks: 0\n",
      "Episode: 118    steps: 52      streaks: 0\n",
      "Episode: 119    steps: 34      streaks: 0\n",
      "Episode: 120    steps: 57      streaks: 0\n",
      "Episode: 121    steps: 39      streaks: 0\n",
      "Loss:  2.12317\n",
      "Episode: 122    steps: 162      streaks: 0\n",
      "Episode: 123    steps: 80      streaks: 0\n",
      "Episode: 124    steps: 85      streaks: 0\n",
      "Episode: 125    steps: 87      streaks: 0\n",
      "Episode: 126    steps: 89      streaks: 0\n",
      "Episode: 127    steps: 106      streaks: 0\n",
      "Episode: 128    steps: 129      streaks: 0\n",
      "Episode: 129    steps: 139      streaks: 0\n",
      "Episode: 130    steps: 95      streaks: 0\n",
      "Episode: 131    steps: 101      streaks: 0\n",
      "Loss:  3.92597\n",
      "Episode: 132    steps: 116      streaks: 0\n",
      "Episode: 133    steps: 114      streaks: 0\n",
      "Episode: 134    steps: 95      streaks: 0\n",
      "Episode: 135    steps: 129      streaks: 0\n",
      "Episode: 136    steps: 159      streaks: 0\n",
      "Episode: 137    steps: 116      streaks: 0\n",
      "Episode: 138    steps: 129      streaks: 0\n",
      "Episode: 139    steps: 187      streaks: 0\n",
      "Episode: 140    steps: 112      streaks: 0\n",
      "Episode: 141    steps: 217      streaks: 0\n",
      "Loss:  3.37476\n",
      "Episode: 142    steps: 47      streaks: 0\n",
      "Episode: 143    steps: 29      streaks: 0\n",
      "Episode: 144    steps: 52      streaks: 0\n",
      "Episode: 145    steps: 19      streaks: 0\n",
      "Episode: 146    steps: 39      streaks: 0\n",
      "Episode: 147    steps: 45      streaks: 0\n",
      "Episode: 148    steps: 22      streaks: 0\n",
      "Episode: 149    steps: 31      streaks: 0\n",
      "Episode: 150    steps: 34      streaks: 0\n",
      "Episode: 151    steps: 41      streaks: 0\n",
      "Loss:  3.60794\n",
      "Episode: 152    steps: 103      streaks: 0\n",
      "Episode: 153    steps: 79      streaks: 0\n",
      "Episode: 154    steps: 70      streaks: 0\n",
      "Episode: 155    steps: 60      streaks: 0\n",
      "Episode: 156    steps: 62      streaks: 0\n",
      "Episode: 157    steps: 88      streaks: 0\n",
      "Episode: 158    steps: 164      streaks: 0\n",
      "Episode: 159    steps: 62      streaks: 0\n",
      "Episode: 160    steps: 55      streaks: 0\n",
      "Episode: 161    steps: 83      streaks: 0\n",
      "Loss:  1.01069\n",
      "Episode: 162    steps: 172      streaks: 0\n",
      "Episode: 163    steps: 91      streaks: 0\n",
      "Episode: 164    steps: 65      streaks: 0\n",
      "Episode: 165    steps: 162      streaks: 0\n",
      "Episode: 166    steps: 80      streaks: 0\n",
      "Episode: 167    steps: 78      streaks: 0\n",
      "Episode: 168    steps: 69      streaks: 0\n",
      "Episode: 169    steps: 70      streaks: 0\n",
      "Episode: 170    steps: 125      streaks: 0\n",
      "Episode: 171    steps: 80      streaks: 0\n",
      "Loss:  1.84014\n",
      "Episode: 172    steps: 11      streaks: 0\n",
      "Episode: 173    steps: 10      streaks: 0\n",
      "Episode: 174    steps: 10      streaks: 0\n",
      "Episode: 175    steps: 10      streaks: 0\n",
      "Episode: 176    steps: 10      streaks: 0\n",
      "Episode: 177    steps: 12      streaks: 0\n",
      "Episode: 178    steps: 10      streaks: 0\n",
      "Episode: 179    steps: 10      streaks: 0\n",
      "Episode: 180    steps: 11      streaks: 0\n",
      "Episode: 181    steps: 11      streaks: 0\n",
      "Loss:  1.05196\n",
      "Episode: 182    steps: 51      streaks: 0\n",
      "Episode: 183    steps: 8      streaks: 0\n",
      "Episode: 184    steps: 29      streaks: 0\n",
      "Episode: 185    steps: 41      streaks: 0\n",
      "Episode: 186    steps: 41      streaks: 0\n",
      "Episode: 187    steps: 10      streaks: 0\n",
      "Episode: 188    steps: 39      streaks: 0\n",
      "Episode: 189    steps: 75      streaks: 0\n",
      "Episode: 190    steps: 33      streaks: 0\n",
      "Episode: 191    steps: 30      streaks: 0\n",
      "Loss:  591.002\n",
      "Episode: 192    steps: 205      streaks: 0\n",
      "Episode: 193    steps: 155      streaks: 0\n",
      "Episode: 194    steps: 102      streaks: 0\n",
      "Episode: 195    steps: 194      streaks: 0\n",
      "Episode: 196    steps: 102      streaks: 0\n",
      "Episode: 197    steps: 240      streaks: 0\n",
      "Episode: 198    steps: 166      streaks: 0\n",
      "Episode: 199    steps: 110      streaks: 0\n",
      "Episode: 200    steps: 166      streaks: 0\n",
      "Episode: 201    steps: 112      streaks: 0\n",
      "Loss:  7.39132\n",
      "Episode: 202    steps: 119      streaks: 0\n",
      "Episode: 203    steps: 121      streaks: 0\n",
      "Episode: 204    steps: 270      streaks: 0\n",
      "Episode: 205    steps: 153      streaks: 0\n",
      "Episode: 206    steps: 105      streaks: 0\n",
      "Episode: 207    steps: 151      streaks: 0\n",
      "Episode: 208    steps: 170      streaks: 0\n",
      "Episode: 209    steps: 138      streaks: 0\n",
      "Episode: 210    steps: 121      streaks: 0\n",
      "Episode: 211    steps: 404      streaks: 0\n",
      "Loss:  0.967156\n",
      "Episode: 212    steps: 156      streaks: 0\n",
      "Episode: 213    steps: 137      streaks: 0\n",
      "Episode: 214    steps: 112      streaks: 0\n",
      "Episode: 215    steps: 160      streaks: 0\n",
      "Episode: 216    steps: 142      streaks: 0\n",
      "Episode: 217    steps: 176      streaks: 0\n",
      "Episode: 218    steps: 205      streaks: 0\n",
      "Episode: 219    steps: 239      streaks: 0\n",
      "Episode: 220    steps: 86      streaks: 0\n",
      "Episode: 221    steps: 239      streaks: 0\n",
      "Loss:  525.576\n",
      "Episode: 222    steps: 48      streaks: 0\n",
      "Episode: 223    steps: 37      streaks: 0\n",
      "Episode: 224    steps: 50      streaks: 0\n",
      "Episode: 225    steps: 63      streaks: 0\n",
      "Episode: 226    steps: 69      streaks: 0\n",
      "Episode: 227    steps: 38      streaks: 0\n",
      "Episode: 228    steps: 70      streaks: 0\n",
      "Episode: 229    steps: 33      streaks: 0\n",
      "Episode: 230    steps: 38      streaks: 0\n",
      "Episode: 231    steps: 68      streaks: 0\n",
      "Loss:  2.53338\n",
      "Episode: 232    steps: 10001      streaks: 1\n",
      "Episode: 233    steps: 10001      streaks: 2\n",
      "Episode: 234    steps: 10001      streaks: 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'flip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-57398e8724df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-57398e8724df>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mbot_play\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainDQN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-40746adfd871>\u001b[0m in \u001b[0;36mbot_play\u001b[0;34m(mainDQN)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreward_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainDQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_mouse_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'flip'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    max_episodes = 5000\n",
    "    max_step_count = 10000    # 충분히 오래 play한 경우 무한 루프(?)를 방지하기 위해 끊음\n",
    "    max_streaks_count = 3    # 충분히 오래 play한 경우가 연속해서 나올 경우, 해당 DQN으로 실제 play를 보자.\n",
    "    streaks_count = 0\n",
    "\n",
    "    # store the previous observations in replay memory\n",
    "    replay_buffer = deque()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        mainDQN = dqn.DQN(sess, input_size, output_size, name=\"main\")\n",
    "        targetDQN = dqn.DQN(sess, input_size, output_size, name=\"target\")\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # initial copy q_net -> target_net\n",
    "        copy_ops = get_copy_var_ops(dest_scope_name=\"target\",\n",
    "                                    src_scope_name=\"main\")\n",
    "        sess.run(copy_ops)\n",
    "        \n",
    "        for episode in range(max_episodes):\n",
    "            e = 1. / ((episode / 10) + 1)\n",
    "            done = False\n",
    "            step_count = 0\n",
    "\n",
    "            state = env.reset()\n",
    "\n",
    "            while not done:\n",
    "                if np.random.rand(1) < e:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    # Choose an action by greedily from the Q-network\n",
    "                    action = np.argmax(mainDQN.predict(state))\n",
    "\n",
    "                # Get new state and reward from environment\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                if done:    # big penalty\n",
    "                    reward = -100\n",
    "\n",
    "                # Save the experience to our buffer\n",
    "                replay_buffer.append((state, action, reward, next_state, done))\n",
    "                if len(replay_buffer) > REPLAY_MEMORY:\n",
    "                    replay_buffer.popleft()\n",
    "\n",
    "                state = next_state\n",
    "                step_count += 1\n",
    "                if step_count > max_step_count:    # Good enough\n",
    "                    streaks_count += 1\n",
    "                    break\n",
    "\n",
    "            if step_count <= max_step_count:\n",
    "                streaks_count = 0\n",
    "\n",
    "            if streaks_count > 0:\n",
    "                print(\"Episode: {}    steps: {}      streaks: {}\".format(episode, step_count, streaks_count))\n",
    "            else:\n",
    "                print(\"Episode: {}    steps: {}\".format(episode, step_count))\n",
    "\n",
    "            if (streaks_count == max_streaks_count):\n",
    "                break;\n",
    "\n",
    "            if step_count > max_step_count:\n",
    "                pass\n",
    "                # break\n",
    "\n",
    "\n",
    "            if episode % 10 ==1:\n",
    "                # Get a random batch of experiences.\n",
    "                for _ in range(50):\n",
    "                    # Minibatch works better\n",
    "                    minibatch = random.sample(replay_buffer, 10)\n",
    "                    loss, _ = replay_train(mainDQN, targetDQN, minibatch)\n",
    "                    \n",
    "                print(\"Loss: \", loss)\n",
    "                # copy q_net => target_net\n",
    "                sess.run(copy_ops)\n",
    "\n",
    "        bot_play(mainDQN)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
